{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image는 width X height X channel 의 pixels로 이루어진 matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- width: 너비로 이미지의 가로 길이를 의미한다.\n",
    "- height: 높이로 이미지의 세로 길이를 의미한다.\n",
    "\n",
    "- pixel: image가 가지고 있는 값으로 width X height 개수만큼 존재한다. image를 표현하는 bit방식에 따라 값의 범위가 달라진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음과 같은 2x2x1 Image가 있을 때"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(i, j)=\\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $f$: image\n",
    "- $i$: height\n",
    "- $j$: width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들어 2번째 픽셀값은 $f(0,1) = 2$와 같이 표현할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 일반적인 Image는 unsigned integer 8bit로 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bit란 2진수로 표현할 수 있는 자릿수의 가장 기본 단위"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\log_{2} {2^{bit}}=bit$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들어, 8bit이면 $2^8=256$이므로,\n",
    "- signed integer이면, 8번째 bit는 부호를 구분하는 bit이고, 나머지 7bit는 값을 표현한다. [-128, 127]까지 표현 가능하다.\n",
    "- unsigned integer이면, 8bit 전부를 값을 표현하는데 사용한다. [0, 255]까지 표현 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bit수가 높아질수록 표현할 수 있는 색의 범위가 증가한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![8bit와 10bit 비교 이미지](./NotebookImage/10bit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 image는 8bit일 경우와 10bit일 경우를 비교한 것이다. bit수가 높을수록 **gradation**이 자연스러워진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Iamge는 Gray-scale Image 3장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install opencv-python # pip\n",
    "#!pip install opencv-python # conda pip\n",
    "#!conda install opencv-python #conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2 # OpenCV python용 라이브러리\n",
    "import os, errno # 각 OS에 맞게 경로와 디렉토리 설정을 위한 라이브러리\n",
    "import numpy as np # 빠른 행렬 연산을 위한 라이브러리\n",
    "import pandas as pd # data를 쉽게 다루기 위한 라이브러리\n",
    "import matplotlib.pyplot as plt # 그래프 및 이미지를 출력하기 위한 라이브러리\n",
    "from tqdm import tqdm_notebook, tqdm # 반복문의 진행정도를 알려주는 라이브러리\n",
    "from jupyterthemes import jtplot # jupyter theme에 맞게 plot을 해주는 라이브러리\n",
    "jtplot.style(theme='grade3', grid=False) # 설정한 테마에 맞게 plot 스타일 변경, grid 설정 끔\n",
    "pd.set_option('display.max_colwidth', 1200) # pandas의 DataFrame에서 최대 column 너비를 1200px로 설정\n",
    "plt.rc('ytick', labelsize=20) # matplotlib의 y축 label size를 20으로 고정\n",
    "plt.rc('xtick', labelsize=20) # matplotlib의 x축 label size를 20으로 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_c = cv2.imread(\"./Sample_Image/Lenna.png\")\n",
    "plt.figure(figsize = (10, 10))\n",
    "plt.imshow(lenna_c[:,:,::-1]) # -1 RGB에서 red와 blue의 순서를 바꿔 준다.\n",
    "#plt.imshow(lenna_c[:,:,::])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 Image는 Image Processing에서 example로 많이 쓰이는 Lenna 사진이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lenna_c.shape)\n",
    "pd.DataFrame(lenna_c[:,:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lenna 사진은 512 X 512 크기의 color 사진이기 때문에 Lenna 사진의 shape이 512 X 512 X 3으로 나타난다.\n",
    "\n",
    "3개의 채널 중 하나를 선택해서 각 pixel들을 출력하면 위의 dataframe과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 color는 빛의 3원색인 Red, Green, Blue (RGB)의 조합으로 표현된다. Lenna 사진의 channel 3개는 RGB 방식의 channel이다.\n",
    "- 주의1) OpenCV의 경우, B, G, R의 순서로 읽는다.\n",
    "- 주의2) OpenCV가 아닌 Matplotlib 등 다른 방식으로 image를 출력하는 경우, R, G, B 순서로 출력한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lenna 사진을 각 channel별로 분리해서 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 20))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"original\", fontsize = 20)\n",
    "plt.imshow(lenna_c[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(\"blue\", fontsize = 20)\n",
    "plt.imshow(lenna_c[:,:,0], cmap = \"gray\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title(\"green\", fontsize = 20)\n",
    "plt.imshow(lenna_c[:,:,1], cmap = \"gray\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title(\"red\", fontsize = 20)\n",
    "plt.imshow(lenna_c[:,:,2], cmap = \"gray\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lenna 사진은 전체적으로 붉은빛을 띄기 때문에 Red Channel image가 밝게 나타난다.\n",
    "- 푸른색 깃털은 Blue Channel에서 밝게 나타난다. Lense flare 효과도 관찰할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 대표 색공간"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RGB 색공간](./NotebookImage/600px-RGBCube_b.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 빨강, 초록, 파랑의 혼합으로 색과 명도를 표현\n",
    "- 색을 혼합할수록 명도가 증가 (가산혼합)\n",
    "- RGBA라고 하여 투명도 A(Alpha)를 추가하여 표현, Alpha가 Max인 pixel은 출력되지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CMYK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CMYK 색공간](./NotebookImage/630px-Synthese-.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **C**yan (청록), **M**agenta (자홍), **Y**ellow (노랑), Blac**k** (검정)\n",
    "- 색을 혼합할수록 명도가 감소 (감산혼합)\n",
    "- 보통 인쇄과정에서 많이 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![HSV 색공간](./NotebookImage/HSV_cone.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hue (색상), Saturation (채도), Value (명도)\n",
    "- 가산 또는 감산 혼합보다 직관적으로 색상 지정 가능\n",
    "- 시각 예술에서 많이 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 대표 Image 파일 확장자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JPEG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JPEG 예시](./NotebookImage/Felis_silvestris_silvestris_small_gradual_decrease_of_quality.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 손실압축 방식을 사용하는 이미지 형식\n",
    "- 파일 크기가 작아 이미지를 보관 및 전송하는데 많이 사용\n",
    "- 압축률이 높을수록 위 고양이 사진의 왼쪽처럼 손상이 많이 발생\n",
    "- YCbCr이라는 색공간을 사용\n",
    "    - Y: 휘도 (밝기 정보)\n",
    "    - CbCr: 색차 (색깔정보)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PNG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png jpeg 비교](./NotebookImage/Comparison_of_JPEG_and_PNG.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 무손실 압축 방식을 사용하는 이미지 형식\n",
    "- JPEG보다 넓은 색깔을 지원\n",
    "- RGB 색공간을 사용\n",
    "- Alpha 채널도 지원"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![opencv](./NotebookImage/225px-OpenCV_Logo_with_text.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Open Source Computer Vision으로 실시간 computer vision을 목적으로 개발된 library\n",
    "- Intel에서 개발하다가 open source화\n",
    "- Cross Platform이기 때문에 Windows, Mac, Linux, OS에 상관없이 동작 가능\n",
    "- C/C++로 개발\n",
    "- Python, JAVA, MATLAB 등에 binding되어 개발 환경 지원"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometric Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![geometric transform](./NotebookImage/perspective.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![segmentation](./NotebookImage/opencv_semantic_segmentation_animation.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ocr](./NotebookImage/ocr_result_05.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 외에도 다양한 Application들이 있으며, 실시간에 초점을 맞추고 나온 library이기 때문에 mobile camera나 로봇 등에 recognition module로 붙여 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIL도 있는데 왜 OpenCV인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PIL은 Python Image Library로 Image를 읽고 쓸 수 있으며, Blur, Contouring, edge finding 등 다양한 filter를 지원한다. 그 외에도 sharpen, contrast 등 image enhancement 관련 기능도 지원한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- OpenCV는 numpy array로 연산하기 때문에 PIL보다 처리 속도가 빠르다.\n",
    "- OpenCV는 numpy로 다루기 때문에 pixel 단위의 가공 및 변환이 PIL보다 더 쉽다.\n",
    "- OpenCV는 python이 나오기 전부터 있었기 때문에 code와 application이 많이 존재해 활용하기 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 광선검 - https://www.youtube.com/watch?v=vaeFCJnIdP0\n",
    "- motion gesture - https://www.youtube.com/watch?v=Fn2ry_9Vxbc\n",
    "- object tracking - https://www.youtube.com/watch?v=3BJFxnap0AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 외 장점은 실습을 하며 알아보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2 # OpenCV python용 라이브러리\n",
    "import os, errno # 각 OS에 맞게 경로와 디렉토리 설정을 위한 라이브러리\n",
    "import numpy as np # 빠른 행렬 연산을 위한 라이브러리\n",
    "import pandas as pd # data를 쉽게 다루기 위한 라이브러리\n",
    "import matplotlib.pyplot as plt # 그래프 및 이미지를 출력하기 위한 라이브러리\n",
    "from tqdm import tqdm_notebook, tqdm # 반복문의 진행정도를 알려주는 라이브러리\n",
    "from jupyterthemes import jtplot # jupyter theme에 맞게 plot을 해주는 라이브러리\n",
    "jtplot.style(theme='grade3', grid=False) # 설정한 테마에 맞게 plot 스타일 변경, grid 설정 끔\n",
    "pd.set_option('display.max_colwidth', 1200) # pandas의 DataFrame에서 최대 column 너비를 1200px로 설정\n",
    "plt.rc('ytick', labelsize=20)\n",
    "plt.rc('xtick', labelsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV는 numpy를 사용하기 때문에 반드시 numpy를 같이 import 해줘야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Read/Write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv2의 imread를 이용해 image를 읽을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_c = cv2.imread(\"./Sample_Image/Lenna.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv2.imread(image file 경로, flag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래와 같은 flag를 통해 읽고 싶은 형태로 image를 읽는 것이 가능\n",
    "- cv2.IMREAD_COLOR: default flag, 1로 표기 가능, color image로 읽기, gray-scale도 color로 읽으니 주의\n",
    "- cv2.IMREAD_GRAYSCALE: 0으로 표기 가능, gray-scale image로 읽기\n",
    "- cv2.IMREAD_UNCHANGED: -1로 표기 가능, alpha channel 포함해서 읽기 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "color image이기 때문에 width, height, channel 형태로 shape이 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### image 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "plt.imshow(lenna_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV는 B, G, R 순서로 읽기 때문에 그냥 출력하면, red channel이 blue로 인식되어 위와 같이 파랗게 출력."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "올바르게 출력시켜주는 방법으론 2가지가 존재\n",
    "1. cv2.cvtColor(image, cv2.COLOR_BGR2RGB)로 변환 후 출력\n",
    "2. image[:,:,::-1], numpy array에서 channel의 순서를 역순으로 하여 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_c_rgb = cv2.cvtColor(lenna_c, cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.imshow(lenna_c_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "plt.imshow(lenna_c[:,:,::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2번이 추가 작업이 없어 더 효율적이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gray-scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_g = cv2.imread(\"./Sample_Image/Lenna.png\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image를 gray-scale로 읽고 싶을 때는 뒤에 file 경로 뒤에 0 또는 cv2.IMREAD_GRAYSCALE 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "plt.imshow(lenna_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그냥 출력하게 되면 matplotlib에서 자동으로 color map을 설정해 푸르게 출력. \n",
    "\n",
    "Gray-scale로 출력하기 원하면, imshow 안에 cmap = \"gray\" 파라미터를 입력."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "plt.imshow(lenna_g, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_g.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gray-scale image이기 때문에 width, height 형태로 shape이 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color with Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opencv_logo = cv2.imread(\"./Sample_Image/OpenCV_Logo_with_text.png\", -1)\n",
    "opencv_logo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alpha channel이 있기 때문에 channel이 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opencv_logo[:,:,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alpha channel이 0이면 투명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "plt.imshow(opencv_logo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.zeros_like(opencv_logo[:,:,3])\n",
    "alpha = alpha + 255\n",
    "opencv_logo[:,:,3] = alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "plt.imshow(opencv_logo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv2의 imwrite를 이용해 image를 저장할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"Lenna_Gray.png\", lenna_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv2.imwrite(file 경로, numpy array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "width X height 또는 width X height X channel로 표현 가능한 numpy array면 저장 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image에서 특정 영역을 잘라내기 위해 아래와 같이 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = int(lenna_c.shape[0]/4)\n",
    "h2 = int(3*(lenna_c.shape[0]/4))\n",
    "w1 = int(lenna_c.shape[1]/4)\n",
    "w2 = int(3*(lenna_c.shape[1]/4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "width와 height의 $[\\frac{1}{4}, \\frac{3}{4}]$ 지점을 위와 같이 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_lenna_c = lenna_c[h1:h2, w1:w2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 좌표 범위의 image 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "plt.imshow(cropped_lenna_c[:,:,::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "크기를 조절할 때 본래는 없는 값을 메우는 작업이 필요한데, 이를 interpolation이라고 하고 OpenCV에서 많이 사용되는 interpolation의 종류는 아래와 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![interpolation](./NotebookImage/Comparison_of_1D_and_2D_interpolation.svg.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cv2.INTER_LINEAR: resize의 default filter로 bilinear interpolation라고도 불린다.\n",
    "- cv2.INTER_NEAREST: nearest neighbor interpolation이라고도 하며, 주변 이웃 pixel값을 가져와 빈공간을 채운다.\n",
    "- cv2.INTER_AREA: 주변 pixel의 관계에 따라 resample하는 방식으로, 크기를 축소할 때 많이 사용한다. 확대할 때는 nearest neighbor와 유사하다.\n",
    "- cv2.INTER_CUBIC - 4x4 이웃 pixel에 대한 bicubic interpolation, bilinear보다 부드럽고 lancozs보다 계산량이 적어 많이 사용된다.\n",
    "- cv2.LANCZOS4 - 8x8 이웃 pixel에 대한lancozs interpolation, 가장 부드럽게 값을 메우지만 연산이 많이 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import itertools\n",
    "import matplotlib.gridspec as gridspec\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard images in imageio\n",
    "ref_images = [\"imageio:coffee.png\", \"imageio:page.png\", \"imageio:immunohistochemistry.png\", \"imageio:horse.png\"] \n",
    "# Limit starting size\n",
    "images_orig = [cv2.resize(imageio.imread(im), (400,400)) for im in ref_images] \n",
    "# interpolation methods to compare\n",
    "methods=[(\"area\", cv2.INTER_AREA), \n",
    "         (\"nearest\", cv2.INTER_NEAREST), \n",
    "         (\"linear\", cv2.INTER_LINEAR), \n",
    "         (\"cubic\", cv2.INTER_CUBIC), \n",
    "         (\"lanczos4\", cv2.INTER_LANCZOS4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(images, titles=['']):\n",
    "    if isinstance(images[0], list):\n",
    "        c = len(images[0])\n",
    "        r = len(images)\n",
    "        images = list(itertools.chain(*images))\n",
    "    else:\n",
    "        c = len(images)\n",
    "        r = 1\n",
    "    plt.figure(figsize=(4*c, 4*r))\n",
    "    gs1 = gridspec.GridSpec(r, c, wspace=0, hspace=0)\n",
    "    #gs1.update(wspace=0.01, hspace=0.01) # set the spacing between axes. \n",
    "    titles = itertools.cycle(titles)\n",
    "    for i in range(r*c):\n",
    "        im = images[i]\n",
    "        title = next(titles)\n",
    "        plt.subplot(gs1[i])\n",
    "        # Don't let imshow doe any interpolation\n",
    "        plt.imshow(im, cmap='gray', interpolation='none')\n",
    "        plt.axis('off')\n",
    "        if i < c:\n",
    "            plt.title(title, fontsize = 20)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50x50 -> 400x400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_small = [cv2.resize(im, (50,50),interpolation=cv2.INTER_AREA) for im in images_orig]\n",
    "image_set = [[cv2.resize(im, (400,400), interpolation=m[1]) for m in methods] for im in images_small]\n",
    "image_set = [[ima,]+imb for ima, imb in zip(images_small, image_set)]\n",
    "names = [\"original 50x50\",] + [m[0]+\" 400x400\" for m in methods]\n",
    "display(image_set, names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- nearest neighbor와 area는 계단현상이 발생\n",
    "- linear는 edge가 smooth된 효과가 발생\n",
    "- cubic과 lancozs는 edge가 가장 shapen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DownSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_set = [[cv2.resize(im, (50,50), interpolation=m[1]) for m in methods] for im in images_orig]\n",
    "image_set = [[ima,]+imb for ima, imb in zip(images_orig, image_set)]\n",
    "names = [\"original 400x400\",] + [m[0]+\" 50x50\" for m in methods]\n",
    "display(image_set, names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- area는 주변 pixel 관계에 따라 resampling하기 때문에 상대적으로 부드럽게 변환\n",
    "- 나마지는 계단 현상이 많이 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculation Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=20\n",
    "data = []\n",
    "scale_factors = [0.05, 0.1, 0.3, 0.5, 0.9, 1.1, 1.5, 2, 4, 7, 12]\n",
    "for m in methods:\n",
    "    for sf in scale_factors:\n",
    "        di = []\n",
    "        for i in range(n):\n",
    "            t0 = time.time()\n",
    "            cv2.resize(images_orig[0], (0,0), fx=sf, fy=sf, interpolation=m[1])\n",
    "            dt = (time.time()-t0)\n",
    "            di.append(dt)\n",
    "        dt = np.mean(di)\n",
    "        err = 2*np.std(di)\n",
    "        data.append(dict(time=dt, method=m[0], err=err, scale=sf))\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = data.groupby(\"method\")\n",
    "plt.figure(figsize=(15,10))\n",
    "for n, gi in g:\n",
    "    plt.plot(gi[\"scale\"], gi[\"time\"], label=n)\n",
    "plt.loglog()\n",
    "plt.legend()\n",
    "plt.xlabel(\"scale factor\", fontsize = 20)\n",
    "plt.ylabel(\"ave time (sec)\", fontsize = 20)\n",
    "plt.title(\"speed comparison\", fontsize = 20)\n",
    "plt.grid(which=\"both\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- nearest가 가장 적은 계산량 요구\n",
    "- downsampling 부분에서는 area가 resampling과정에서 가장 높은 계산량 요구\n",
    "- linear와 cubic은 가성비가 높은 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_c = cv2.imread(\"./Sample_Image/Lenna.png\")\n",
    "plt.figure(figsize = (20, 20))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"original\", fontsize = 20)\n",
    "plt.imshow(lenna_c[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(\"blue\", fontsize = 20)\n",
    "plt.imshow(lenna_c[:,:,0], cmap = \"gray\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title(\"green\", fontsize = 20)\n",
    "plt.imshow(lenna_c[:,:,1], cmap = \"gray\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title(\"red\", fontsize = 20)\n",
    "plt.imshow(lenna_c[:,:,2], cmap = \"gray\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image에서 어떤 채널이 영향이 큰지 확인하기 위해, 위와 같이 일일히 channel별로 출력하는 것은 비효율적이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래서 각 channel별로 **histogram**을 통해 수치적으로 색들의 분포를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = ('b','g','r')\n",
    "plt.figure(figsize = (15, 10))\n",
    "for i,col in enumerate(color):\n",
    "    histr = cv2.calcHist([lenna_c],[i],None,[256],[0,256])\n",
    "    plt.plot(histr,color = col)\n",
    "    plt.xlim([0,256])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "세로축은 frequency이며, 가로축은 pixel값이다. pixel값이 클수록 밝다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "red channel에 밝은 값들이 많이 몰려있다는 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Remove Red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_c_remove_red = lenna_c.copy()\n",
    "lenna_c_remove_red[:,:,2] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original image를 copy한 후, red channel의 성분을 전부 0으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"original\", fontsize = 20)\n",
    "plt.imshow(lenna_c[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"remove red\", fontsize = 20)\n",
    "plt.imshow(lenna_c_remove_red[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "color = ('b','g','r')\n",
    "plt.figure(figsize = (18, 20))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title(\"original\", fontsize = 20)\n",
    "for i,col in enumerate(color):\n",
    "    histr = cv2.calcHist([lenna_c],[i],None,[256],[0,256])\n",
    "    plt.plot(histr,color = col)\n",
    "    plt.xlim([0,256])\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title(\"remove red\", fontsize = 20)\n",
    "for i,col in enumerate(color):\n",
    "    histr = cv2.calcHist([lenna_c_remove_red],[i],None,[256],[0,256])\n",
    "    plt.plot(histr,color = col)\n",
    "    plt.xlim([0,256])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram_for_color_image(image):\n",
    "    color = ('b','g','r')\n",
    "    plt.figure(figsize = (15, 10))\n",
    "    for i,col in enumerate(color):\n",
    "        histr = cv2.calcHist([image],[i],None,[256],[0,256])\n",
    "        plt.plot(histr,color = col)\n",
    "        plt.xlim([0,256])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Colorspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv2.cvtColor(input_image, flag)\n",
    "- flag로 색공간을 결정한다.\n",
    "- 다양한 색공간을 지원한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BGR->GRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_cvt_g = cv2.cvtColor(lenna_c, cv2.COLOR_BGR2GRAY)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"read\", fontsize = 20)\n",
    "plt.imshow(lenna_g, cmap = \"gray\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"convert\", fontsize = 20)\n",
    "plt.imshow(lenna_cvt_g, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_cvt_g_histogram = cv2.calcHist([lenna_cvt_g],[0],None,[256],[0,256])\n",
    "plt.figure(figsize = (15, 10))\n",
    "plt.plot(lenna_cvt_g_histogram)\n",
    "plt.figure(figsize = (15, 10))\n",
    "histr_g = cv2.calcHist([lenna_g],[0],None,[256],[0,256])\n",
    "plt.plot(histr_g)\n",
    "plt.xlim([0,256])\n",
    "plt.xlim([0,256])\n",
    "plot_histogram_for_color_image(lenna_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRAY -> BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_cvt_c = cv2.cvtColor(lenna_cvt_g, cv2.COLOR_GRAY2BGR)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"convert\", fontsize = 20)\n",
    "plt.imshow(lenna_cvt_c[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_for_color_image(lenna_cvt_c)\n",
    "plot_histogram_for_color_image(lenna_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BGR -> HSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_cvt_hsv = cv2.cvtColor(lenna_c, cv2.COLOR_BGR2HSV)\n",
    "lenna_cvt_hsv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HUE"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "hue = lenna_cvt_hsv[:,:,0]\n",
    "plt.figure(figsize = (15, 10))\n",
    "histr_hue = cv2.calcHist([hue],[0],None,[180],[0,180])\n",
    "hue_range = np.arange(180)\n",
    "colors = cm.hsv(hue_range / float(max(hue_range)))\n",
    "plt.bar(hue_range, histr_hue[:,0], color=colors, log = True)\n",
    "plt.xlim([0,180])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saturation = lenna_cvt_hsv[:,:,1]\n",
    "plt.figure(figsize = (15, 10))\n",
    "histr_sat = cv2.calcHist([saturation],[0],None,[256],[0,256])\n",
    "plt.xlim([0,256])\n",
    "plt.plot(histr_sat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = lenna_cvt_hsv[:,:,2]\n",
    "plt.figure(figsize = (15, 10))\n",
    "histr_val = cv2.calcHist([value],[0],None,[256],[0,256])\n",
    "plt.xlim([0,256])\n",
    "plt.plot(histr_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HSV -> BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_cvt_hsv_c = cv2.cvtColor(lenna_cvt_hsv, cv2.COLOR_HSV2BGR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brightness와 Contrast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brightness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image의 pixel값이 클수록 밝아지기 때문에 이미지의 밝기를 조절하기 가장 쉬운 방법은 pixel에 특정값을 더하고 빼는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image를 밝게하기 위해서 그냥 더하면 아래와 같은 결과를 얻을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_c_bright = lenna_c + 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"original\", fontsize = 20)\n",
    "plt.imshow(lenna_c[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"bright\", fontsize = 20)\n",
    "plt.imshow(lenna_c_bright[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자세히 보면 밝은 부위만 색이 깨진 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_for_color_image(lenna_c)\n",
    "plot_histogram_for_color_image(lenna_c_bright)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "histogram이 밝은 쪽으로 shift 되고 큰 값들은 순환해서 0쪽에 있는 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "즉, 그냥 값을 더하면 red channel의 밝은 값들이 어두운 값으로 이동하고 그에 따라 초록색과 파란색이 두드러지게 된 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이와 같은 현상이 발생한 이유는 numpy의 unsigned integer가 값이 순환되기 때문이다. 이를, 방지하기 위해 아래와 같이 작업을 수행한다.\n",
    "1. unsigned integer 8bit -> 더 높은 bit\n",
    "2. pixel값을 조작\n",
    "3. 값의 범위를 0 ~ 255로 제한\n",
    "4. unsigned integer 8bit으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_c_bright = np.clip((lenna_c.astype(np.int16) + 50), 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy의 clip method를 사용하면 최댓값과 쵯솟값을 제한할 수 있다.\n",
    "\n",
    "그래서 255보다 큰 값들을 255로, 0보다 작은 값은 0으로 제한함으로서 image가 밝아지는 효과를 얻을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"original\", fontsize = 20)\n",
    "plt.imshow(lenna_c[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"bright\", fontsize = 20)\n",
    "plt.imshow(lenna_c_bright[:,:,::-1])\n",
    "plt.xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_for_color_image(lenna_c)\n",
    "plot_histogram_for_color_image(lenna_c_bright)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어둡게 하기 위해선 값을 빼면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_c_darken = np.clip((lenna_c.astype(np.int16) - 50), 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"original\", fontsize = 20)\n",
    "plt.imshow(lenna_c[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"darken\", fontsize = 20)\n",
    "plt.imshow(lenna_c_darken[:,:,::-1])\n",
    "plt.xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_for_color_image(lenna_c)\n",
    "plot_histogram_for_color_image(lenna_c_darken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gamma을 통한 contrast 조절"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$g(i, j)=\\gamma f(i, j)+\\beta$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $g$는 결과 image\n",
    "- $f$는 원본 image\n",
    "- $i$: row\n",
    "- $j$: height\n",
    "- $\\gamma$: gain, contrast를 조절하는 값\n",
    "- $\\beta$: bias, 밝기를 조절하는 값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\gamma$만 Lenna image에 적용하면 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_c_gamma1 = np.clip(2.1*(lenna_c.astype(np.int16)), 0, 255).astype(np.uint8)\n",
    "lenna_c_gamma2 = np.clip(0.6*(lenna_c.astype(np.int16)), 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (30,10))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"original\", fontsize = 20)\n",
    "plt.imshow(lenna_c[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"gamma1\", fontsize = 20)\n",
    "plt.imshow(lenna_c_gamma1[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"gamma2\", fontsize = 20)\n",
    "plt.imshow(lenna_c_gamma2[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_c_contrast1 = np.clip(2.1*(lenna_c.astype(np.int16))-50, 0, 255).astype(np.uint8)\n",
    "lenna_c_contrast2 = np.clip(0.6*(lenna_c.astype(np.int16))+20, 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (30,10))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"original\", fontsize = 20)\n",
    "plt.imshow(lenna_c[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"contrast1\", fontsize = 20)\n",
    "plt.imshow(lenna_c_contrast1[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"contrast2\", fontsize = 20)\n",
    "plt.imshow(lenna_c_contrast2[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\gamma$와 $\\beta$를 조작해 contrast를 조절할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histgram Equalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image의 histogram이 골고루 분포하도록 histgram을 늘려주는 방법이다. histogram strach 또는 Normalization이라고도 한다.\n",
    "\n",
    "OpenCV를 통해 다음과 같이 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_b_eq = cv2.equalizeHist(lenna_c[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"original\", fontsize = 20)\n",
    "plt.imshow(lenna_c[:,:,0], cmap = \"gray\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"equalized histogram\", fontsize = 20)\n",
    "plt.imshow(lenna_b_eq, cmap = \"gray\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16, 10))\n",
    "histr_lenna_c = cv2.calcHist([lenna_c],[0],None,[256],[0,256])\n",
    "plt.plot(histr)\n",
    "plt.xlim([0,256])\n",
    "plt.figure(figsize = (16, 10))\n",
    "histr_lenna_b_eq = cv2.calcHist([lenna_b_eq],[0],None,[256],[0,256])\n",
    "plt.plot(histr)\n",
    "plt.xlim([0,256])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 channel에만 사용 가능하기 때문에 color image에 적용하기 위해선 아래와 같이 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_c_equalized = np.dstack((cv2.equalizeHist(lenna_c[:,:,0]), cv2.equalizeHist(lenna_c[:,:,1])))\n",
    "lenna_c_equalized = np.dstack((lenna_c_equalized, cv2.equalizeHist(lenna_c[:,:,2])))\n",
    "lenna_c_equalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"original\", fontsize = 20)\n",
    "plt.imshow(lenna_c[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"equalized histogram\", fontsize = 20)\n",
    "plt.imshow(lenna_c_equalized[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_for_color_image(lenna_c)\n",
    "plot_histogram_for_color_image(lenna_c_equalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_c_normalized = cv2.normalize(lenna_c, None, 0, 255, norm_type=cv2.NORM_MINMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"original\", fontsize = 20)\n",
    "plt.imshow(lenna_c[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"normalization\", fontsize = 20)\n",
    "plt.imshow(lenna_c_normalized[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram_for_color_image(lenna_c)\n",
    "plot_histogram_for_color_image(lenna_c_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saturation와 Brightness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_cvt_hsv = cv2.cvtColor(lenna_c, cv2.COLOR_BGR2HSV)\n",
    "lenna_cvt_hsv_low_sat = lenna_cvt_hsv.copy()\n",
    "lenna_cvt_hsv_high_sat = lenna_cvt_hsv.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_cvt_hsv_low_sat[:,:,1] = np.clip((lenna_cvt_hsv_low_sat[:,:,1].astype(np.int16) - 50), 0, 255).astype(np.uint8)\n",
    "lenna_cvt_hsv_high_sat[:,:,1] = np.clip((lenna_cvt_hsv_high_sat[:,:,1].astype(np.int16) + 50), 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_low_sat = cv2.cvtColor(lenna_cvt_hsv_low_sat, cv2.COLOR_HSV2BGR)\n",
    "lenna_high_sat = cv2.cvtColor(lenna_cvt_hsv_high_sat, cv2.COLOR_HSV2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (30,10))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"original\", fontsize = 20)\n",
    "plt.imshow(lenna_c[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"low saturation\", fontsize = 20)\n",
    "plt.imshow(lenna_low_sat[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"high saturation\", fontsize = 20)\n",
    "plt.imshow(lenna_high_sat[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_cvt_hsv = cv2.cvtColor(lenna_c, cv2.COLOR_BGR2HSV)\n",
    "lenna_cvt_hsv_low_value = lenna_cvt_hsv.copy()\n",
    "lenna_cvt_hsv_high_value = lenna_cvt_hsv.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_cvt_hsv_low_value[:,:,2] = np.clip((lenna_cvt_hsv_low_value[:,:,2].astype(np.int16) - 50), 0, 255).astype(np.uint8)\n",
    "lenna_cvt_hsv_high_value[:,:,2] = np.clip((lenna_cvt_hsv_high_value[:,:,2].astype(np.int16) + 50), 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_low_value = cv2.cvtColor(lenna_cvt_hsv_low_value, cv2.COLOR_HSV2BGR)\n",
    "lenna_high_value = cv2.cvtColor(lenna_cvt_hsv_high_value, cv2.COLOR_HSV2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (30,10))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"original\", fontsize = 20)\n",
    "plt.imshow(lenna_c[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"low value\", fontsize = 20)\n",
    "plt.imshow(lenna_low_value[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"high value\", fontsize = 20)\n",
    "plt.imshow(lenna_high_value[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = lenna_g\n",
    "ret,thresh1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "ret,thresh2 = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV)\n",
    "ret,thresh3 = cv2.threshold(img,127,255,cv2.THRESH_TRUNC)\n",
    "ret,thresh4 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO)\n",
    "ret,thresh5 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "titles = ['Original Image','BINARY','BINARY_INV','TRUNC','TOZERO','TOZERO_INV']\n",
    "images = [img, thresh1, thresh2, thresh3, thresh4, thresh5]\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i], fontsize = 20)\n",
    "    plt.xticks([]),plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width, channels = lenna_c.shape # image의 shape를 통해서 height와 width를 추출\n",
    "rotation_angle = 90 # numpy random으로 회전할 각도 선택\n",
    "Rot_M = cv2.getRotationMatrix2D((width/2, height/2), rotation_angle, 1)\n",
    "# openCV의 getRotationMatrix2D를 통해 회전할 각도만큼 회전하는 matrix 생성\n",
    "lenna_c_rotate90 = cv2.warpAffine(lenna_c, Rot_M, (width, height))\n",
    "rotation_angle = 180 # numpy random으로 회전할 각도 선택\n",
    "Rot_M = cv2.getRotationMatrix2D((width/2, height/2), rotation_angle, 1)\n",
    "# openCV의 getRotationMatrix2D를 통해 회전할 각도만큼 회전하는 matrix 생성\n",
    "lenna_c_rotate180 = cv2.warpAffine(lenna_c, Rot_M, (width, height))\n",
    "rotation_angle = 270 # numpy random으로 회전할 각도 선택\n",
    "Rot_M = cv2.getRotationMatrix2D((width/2, height/2), rotation_angle, 1)\n",
    "# openCV의 getRotationMatrix2D를 통해 회전할 각도만큼 회전하는 matrix 생성\n",
    "lenna_c_rotate270 = cv2.warpAffine(lenna_c, Rot_M, (width, height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. openCV의 getRotationMatrix2D를 통해 회전하기 희망하는 각도로 회전할 수 있게 index가 설정된 matrix를 생성\n",
    "2. warpAffine을 통해 1번에서 생성된 matrix와 mapping하여 회전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,20))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.title(\"original\", fontsize = 20)\n",
    "plt.imshow(lenna_c[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.title(\"90\", fontsize = 20)\n",
    "plt.imshow(lenna_c_rotate90[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.title(\"180\", fontsize = 20)\n",
    "plt.imshow(lenna_c_rotate180[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.title(\"270\", fontsize = 20)\n",
    "plt.imshow(lenna_c_rotate270[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenna_c_vertical = cv2.flip(lenna_c, 0) # 상하 뒤집기\n",
    "lenna_c_horizontal = cv2.flip(lenna_c, 1) # 좌우 뒤집기\n",
    "lenna_c_horizontal_vertical = cv2.flip(lenna_c_horizontal, 0) # 좌우 뒤집기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "openCV의 flip method를 통해 뒤집기를 수행\n",
    "- 0이면 vertical flip\n",
    "- 1이면 horizontal flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,20))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.title(\"original\", fontsize = 20)\n",
    "plt.imshow(lenna_c[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.title(\"vertical\", fontsize = 20)\n",
    "plt.imshow(lenna_c_vertical[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.title(\"horizontal\", fontsize = 20)\n",
    "plt.imshow(lenna_c_horizontal[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.title(\"horizontal & vertical\", fontsize = 20)\n",
    "plt.imshow(lenna_c_horizontal_vertical[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur3 = cv2.blur(lenna_c,(3,3))\n",
    "blur5 = cv2.blur(lenna_c,(5,5))\n",
    "blur7 = cv2.blur(lenna_c,(7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,20))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.title(\"original\", fontsize = 20)\n",
    "plt.imshow(lenna_c[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.title(\"3 x 3\", fontsize = 20)\n",
    "plt.imshow(blur3[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.title(\"5 x 5\", fontsize = 20)\n",
    "plt.imshow(blur5[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.title(\"7 x 7\", fontsize = 20)\n",
    "plt.imshow(blur7[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gblur3 = cv2.GaussianBlur(lenna_c,(3,3), 0)\n",
    "Gblur5 = cv2.GaussianBlur(lenna_c,(5,5), 0)\n",
    "Gblur7 = cv2.GaussianBlur(lenna_c,(7,7), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,20))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.title(\"original\", fontsize = 20)\n",
    "plt.imshow(lenna_c[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.title(\"3 x 3\", fontsize = 20)\n",
    "plt.imshow(Gblur3[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.title(\"5 x 5\", fontsize = 20)\n",
    "plt.imshow(Gblur5[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.title(\"7 x 7\", fontsize = 20)\n",
    "plt.imshow(Gblur7[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gblur72 = cv2.GaussianBlur(lenna_c,(7,7), 2)\n",
    "Gblur74 = cv2.GaussianBlur(lenna_c,(7,7), 4)\n",
    "Gblur78 = cv2.GaussianBlur(lenna_c,(7,7), 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,20))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"original\", fontsize = 20)\n",
    "plt.imshow(lenna_c[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(\"std = 2\", fontsize = 20)\n",
    "plt.imshow(Gblur72[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title(\"std = 4\", fontsize = 20)\n",
    "plt.imshow(Gblur74[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title(\"std = 8\", fontsize = 20)\n",
    "plt.imshow(Gblur78[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mblur3 = cv2.medianBlur(lenna_c, 3)\n",
    "Mblur5 = cv2.medianBlur(lenna_c, 5)\n",
    "Mblur7 = cv2.medianBlur(lenna_c, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,20))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.title(\"original\", fontsize = 20)\n",
    "plt.imshow(lenna_c[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.title(\"3 x 3\", fontsize = 20)\n",
    "plt.imshow(Mblur3[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.title(\"5 x 5\", fontsize = 20)\n",
    "plt.imshow(Mblur5[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.title(\"7 x 7\", fontsize = 20)\n",
    "plt.imshow(Mblur7[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharpen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_sharpen = np.array([[-1, -1, -1], [-1, 9, -1], [-1 ,-1, -1]])\n",
    "sharpen = cv2.filter2D(lenna_c, -1, kernel_sharpen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"original\", fontsize = 20)\n",
    "plt.imshow(lenna_c[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"sharpen\", fontsize = 20)\n",
    "plt.imshow(sharpen[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsharp Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_lenna_c = cv2.GaussianBlur(lenna_c, (9,9), 10.0)\n",
    "unsharp_lenna_c = cv2.addWeighted(lenna_c, 1.5, gauss_lenna_c, -0.5, 0, lenna_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"original\", fontsize = 20)\n",
    "plt.imshow(lenna_c[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"unsharp masking\", fontsize = 20)\n",
    "plt.imshow(unsharp_lenna_c[:,:,::-1])\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian = cv2.Laplacian(lenna_g,cv2.CV_64F)\n",
    "laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"original\", fontsize = 20)\n",
    "plt.imshow(lenna_g, cmap = \"gray\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"laplacian\", fontsize = 20)\n",
    "plt.imshow(np.clip(laplacian,0,255), cmap = \"gray\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobelx = cv2.Sobel(lenna_g, cv2.CV_64F, 1, 0, ksize=5)\n",
    "sobely = cv2.Sobel(lenna_g, cv2.CV_64F, 0, 1, ksize=5)\n",
    "sobel = cv2.Sobel(lenna_g, cv2.CV_64F, 1, 1, ksize=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,20))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"original\", fontsize = 20)\n",
    "plt.imshow(lenna_g, cmap = \"gray\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(\"sobel x\", fontsize = 20)\n",
    "plt.imshow(np.clip(sobelx, 0, 255), cmap = \"gray\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title(\"sobel y\", fontsize = 20)\n",
    "plt.imshow(np.clip(sobely, 0, 255), cmap = \"gray\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title(\"sobel\", fontsize = 20)\n",
    "plt.imshow(np.clip(sobel, 0, 255), cmap = \"gray\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny = cv2.Canny(lenna_g,100,200, 5)\n",
    "canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"original\", fontsize = 20)\n",
    "plt.imshow(lenna_g, cmap = \"gray\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"canny\", fontsize = 20)\n",
    "plt.imshow(canny, cmap = \"gray\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,20))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"original\", fontsize = 20)\n",
    "plt.imshow(lenna_g, cmap = \"gray\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(\"laplacian\", fontsize = 20)\n",
    "plt.imshow(np.clip(laplacian, 0, 255), cmap = \"gray\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title(\"sobel\", fontsize = 20)\n",
    "plt.imshow(np.clip(sobel, 0, 255), cmap = \"gray\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title(\"canny\", fontsize = 20)\n",
    "plt.imshow(canny, cmap = \"gray\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_example = cv2.imread(\"./Sample_Image/resize example.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "plt.imshow(line_example, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_example_edges = cv2.Canny(line_example, 50,150, apertureSize=3)\n",
    "lines = cv2.HoughLines(line_example_edges, 1, np.pi/180, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "plt.imshow(line_example_edges, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_example_original = line_example.copy()\n",
    "for i in range(len(lines)):\n",
    "    for rho, theta in lines[i]:\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a*rho\n",
    "        y0 = b*rho\n",
    "        x1 = int(x0 + 1000*(-b))\n",
    "        y1 = int(y0+1000*(a))\n",
    "        x2 = int(x0 - 1000*(-b))\n",
    "        y2 = int(y0 -1000*(a))\n",
    "\n",
    "        cv2.line(line_example,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "\n",
    "res = np.vstack((line_example_original,line_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 20))\n",
    "plt.imshow(res[:,:,::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circle Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./Sample_Image/OpenCV_Logo_with_text.png',0)\n",
    "img = cv2.medianBlur(img, 5)\n",
    "cimg = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 20))\n",
    "plt.imshow(img, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circles = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT, 1, 40,param1=50,param2=30,minRadius=0, maxRadius=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circles = np.uint16(np.around(circles))\n",
    "\n",
    "for i in circles[0,:]:\n",
    "    cv2.circle(cimg,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "    cv2.circle(cimg,(i[0],i[1]),2,(0,0,255),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 20))\n",
    "plt.imshow(cimg, cmap = \"gray\")\n",
    "plt.title(\"Circle Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

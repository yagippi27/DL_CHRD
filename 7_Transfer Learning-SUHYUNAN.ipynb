{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DCQZGS8zz_nT"
   },
   "source": [
    "# Lecture 7. Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YdXzKkawz_nY"
   },
   "source": [
    "## Transfer learning\n",
    "- 큰 데이터 셋에서 학습된 pretrained network의 weight를 사용하여 다른 예측문제에 활용 \n",
    "    - 예) 동물과 일상과 관련된 사물을 분류하는 ImageNet data를 학습시킨 VGG16 네트워크의 일부를 사용하여 가구 종류를 분류하는 네트워크 학습에 활용 \n",
    "- Convolution base만 활용\n",
    "    - Convolution base는 사진에 나타나는 일반적인 개체의  특성을 파악하기 위한 feature extraction의 결과물 \n",
    "    - Classifier 부분은 분류 목적에 맞게 특성화 된 부분\n",
    "    - Fully connected layer 부분은 개체의 location에 대한 정보를 잃어버린 상태(flattened)\n",
    "- 기존 모형이 학습한 데이터와 많이 다른 데이터에 적용하기 위해서는 앞의 몇 개 layer만 사용하는 것이 더 나음 \n",
    "    - 앞 쪽의 layer은 지엽적이고 일반적인 feature map(e.g. visual edges, colors, and textures)\n",
    "    - 더 깊은 부분의 layer는 보다 추상화된 feature map(e.g. \"cat ear\", \"dog eye\")\n",
    "- 두 가지 방법 (1) Feature extraction, (2) Fine tuning 을 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_cZQ00wLz_na"
   },
   "source": [
    "## 7.1 Feature extraction\n",
    "- 기존의 학습된 network에서 fully connected layer를 제외한 나머지 weight를 고정하고 새로운 목적에 맞는 fully connected layer를 추가하여 추가된 weight만 학습하는 방법\n",
    "- `keras.applications` module이 지원하는  image classification models\n",
    "    - Xception\n",
    "    - VGG16\n",
    "    - VGG19\n",
    "    - ResNet50\n",
    "    - InceptionV3\n",
    "    - InceptionResNetV2\n",
    "    - MobileNet\n",
    "    - DenseNet\n",
    "    - NASNet\n",
    "    - MobileNetV2\n",
    "    \n",
    "    https://keras.io/applications/\n",
    "<img src=\"figures/transfer.PNG\" width=\"50%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3385,
     "status": "ok",
     "timestamp": 1575905869716,
     "user": {
      "displayName": "김동욱",
      "photoUrl": "",
      "userId": "05759155305116110709"
     },
     "user_tz": -540
    },
    "id": "RaGsVtKIz_nd",
    "outputId": "9c427327-4356-484e-8933-c1933a841fa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.17.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install h5py \n",
    "#!pip install pillow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AdnKcWoMz_nl"
   },
   "source": [
    "#### Instantiating the VGG16 convolutional base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T05:18:14.050645Z",
     "start_time": "2018-07-14T05:17:15.075851Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "2WZpR7Mpz_nm"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cmm2OFN8z_oI"
   },
   "source": [
    "- Imagenet의 1000개의 카테고리를 분류하는 문제에 학습된 VGG16의 network와 weight를 불러옴 \n",
    "    - `weights`: 모형의 weight의 초기값 \n",
    "    - `include_top`: densely connected classifier를 포함할지 여부 \n",
    "    - `input_shape`: 사용자가 입력할 이미지의 크기 shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T05:35:15.988207Z",
     "start_time": "2018-07-14T05:35:15.977283Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 826
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 557,
     "status": "ok",
     "timestamp": 1575905874456,
     "user": {
      "displayName": "김동욱",
      "photoUrl": "",
      "userId": "05759155305116110709"
     },
     "user_tz": -540
    },
    "id": "cWX6oWs3z_oq",
    "outputId": "569dbdbe-2fdb-4a33-ed5e-0c78cda84e59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FAgWMBDGz_ps"
   },
   "source": [
    "#### Feature extraction의 두 가지 방법\n",
    "1. 위의 `conv_base`에 새로운 데이터를 입력하여 출력값을 numpy 배열로 저장하고 이를 새로운 모델의 입력값으로 사용. Convolution operation을 하지 않아도 되기 때문에 빠르게 학습. 하지만 data augmentation 방법을 사용할 수 없음.\n",
    "2. `conv_base` 이후에 새로운 layer를 쌓아 확장한 뒤 전체 모델을 다시 학습. 모든 데이터가 convolution layer들을 통과해야 하기 때문에 학습이 느림. data augmentation 방법을 사용할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6oblcXwbz_p3"
   },
   "source": [
    "### 7.1.1 Feature extraction without data augmentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pZe6Sw3zz_qV"
   },
   "source": [
    "- `conv_base`의 predict 메소드로 입력 이미지의 feature를 추출 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iPRm41l8z_qX"
   },
   "outputs": [],
   "source": [
    "# train, validation, test 이미지가 들어있는 폴더 경로를 지정\n",
    "train_dir = './data/cats_and_dogs_small/train'\n",
    "validation_dir = './data/cats_and_dogs_small/validation'\n",
    "test_dir = './data/cats_and_dogs_small/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 585,
     "status": "error",
     "timestamp": 1575906017891,
     "user": {
      "displayName": "김동욱",
      "photoUrl": "",
      "userId": "05759155305116110709"
     },
     "user_tz": -540
    },
    "id": "YoiVwGHOz_ql",
    "outputId": "5e26f949-b38a-4b41-ba49-294c7cd96ec9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            # Note that since generators yield data indefinitely in a loop,\n",
    "            # we must `break` after every image has been seen once.\n",
    "            break\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_dir, 2000)\n",
    "validation_features, validation_labels = extract_features(validation_dir, 1000)\n",
    "test_features, test_labels = extract_features(test_dir, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mjXCA2dOz_rq",
    "outputId": "ace2180f-fc2e-4ddc-d510-afff7ca90fed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 4, 4, 512), (2000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h2UgHGh8z_r2"
   },
   "source": [
    "- 출력된 feature가 4D array이기 때문에 새로운 DNN 모델에 입력으로 넣기 위해 2D array로 변환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5wp7MIc8z_r7"
   },
   "outputs": [],
   "source": [
    "train_features = np.reshape(train_features, (2000, 4 * 4 * 512))\n",
    "validation_features = np.reshape(validation_features, (1000, 4 * 4 * 512))\n",
    "test_features = np.reshape(test_features, (1000, 4 * 4 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AaSogTCwz_r-",
    "outputId": "fe463969-e7e8-426f-8c6c-efe9687077c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 8192)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4k1j2iHMz_sD",
    "outputId": "97a57b18-26e5-4889-ac03-b379763da814",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\keras\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\keras\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "2000/2000 [==============================] - 3s 2ms/step - loss: 0.5939 - acc: 0.6740 - val_loss: 0.4170 - val_acc: 0.8340\n",
      "Epoch 2/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.4252 - acc: 0.8045 - val_loss: 0.3440 - val_acc: 0.8630\n",
      "Epoch 3/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.3509 - acc: 0.8500 - val_loss: 0.3066 - val_acc: 0.8770\n",
      "Epoch 4/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.3121 - acc: 0.8745 - val_loss: 0.2863 - val_acc: 0.8860\n",
      "Epoch 5/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.2763 - acc: 0.8815 - val_loss: 0.2740 - val_acc: 0.8870\n",
      "Epoch 6/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.2594 - acc: 0.9010 - val_loss: 0.2649 - val_acc: 0.8930\n",
      "Epoch 7/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.2404 - acc: 0.9110 - val_loss: 0.2533 - val_acc: 0.9000\n",
      "Epoch 8/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.2233 - acc: 0.9155 - val_loss: 0.2672 - val_acc: 0.8840\n",
      "Epoch 9/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.2061 - acc: 0.9120 - val_loss: 0.2430 - val_acc: 0.8990\n",
      "Epoch 10/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.2043 - acc: 0.9180 - val_loss: 0.2399 - val_acc: 0.9040\n",
      "Epoch 11/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1872 - acc: 0.9365 - val_loss: 0.2372 - val_acc: 0.9060\n",
      "Epoch 12/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1775 - acc: 0.9300 - val_loss: 0.2353 - val_acc: 0.9080\n",
      "Epoch 13/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1688 - acc: 0.9425 - val_loss: 0.2330 - val_acc: 0.9070\n",
      "Epoch 14/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1596 - acc: 0.9465 - val_loss: 0.2388 - val_acc: 0.8950\n",
      "Epoch 15/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1584 - acc: 0.9460 - val_loss: 0.2319 - val_acc: 0.9060\n",
      "Epoch 16/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1483 - acc: 0.9450 - val_loss: 0.2355 - val_acc: 0.8990\n",
      "Epoch 17/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1397 - acc: 0.9565 - val_loss: 0.2385 - val_acc: 0.8970\n",
      "Epoch 18/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1333 - acc: 0.9580 - val_loss: 0.2488 - val_acc: 0.8970\n",
      "Epoch 19/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1302 - acc: 0.9565 - val_loss: 0.2327 - val_acc: 0.9060\n",
      "Epoch 20/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1212 - acc: 0.9600 - val_loss: 0.2296 - val_acc: 0.9080\n",
      "Epoch 21/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1227 - acc: 0.9565 - val_loss: 0.2467 - val_acc: 0.8980\n",
      "Epoch 22/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1169 - acc: 0.9605 - val_loss: 0.2404 - val_acc: 0.8980\n",
      "Epoch 23/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1083 - acc: 0.9610 - val_loss: 0.2294 - val_acc: 0.9100\n",
      "Epoch 24/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1021 - acc: 0.9650 - val_loss: 0.2542 - val_acc: 0.8950\n",
      "Epoch 25/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.0994 - acc: 0.9685 - val_loss: 0.2361 - val_acc: 0.9040\n",
      "Epoch 26/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.0933 - acc: 0.9730 - val_loss: 0.2308 - val_acc: 0.9050\n",
      "Epoch 27/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.0904 - acc: 0.9745 - val_loss: 0.2319 - val_acc: 0.9060\n",
      "Epoch 28/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.0886 - acc: 0.9765 - val_loss: 0.2536 - val_acc: 0.8980\n",
      "Epoch 29/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.0865 - acc: 0.9745 - val_loss: 0.2322 - val_acc: 0.9060\n",
      "Epoch 30/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.0808 - acc: 0.9750 - val_loss: 0.2331 - val_acc: 0.9060\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    epochs=30,\n",
    "                    batch_size=20,\n",
    "                    validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N74x0ZpMz_sO",
    "outputId": "62caa9a3-d3dd-4263-fdb5-2b1f57ab2d9b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1OgTITBwz_sQ"
   },
   "source": [
    "- 학습 속도가 매우 빠름\n",
    "- 90% 정도의 validation accuracy에 도달함\n",
    "- 이미지 증식을 하지 않았기 때문에 overfitting이 발생함 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NoOwjN8Cz_sS"
   },
   "source": [
    "### 7.1.2 Feature extraction with data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PcNGmxvlz_sT"
   },
   "source": [
    "- VGG16의 network에 fully connected layer를 추가하여 모형 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T05:35:18.122146Z",
     "start_time": "2018-07-14T05:35:18.019260Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "WarQt8xJz_sU"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras import optimizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T05:35:19.253670Z",
     "start_time": "2018-07-14T05:35:19.242700Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "InR93busz_sa",
    "outputId": "8c58a912-a09c-4fdf-bb58-de7c9a35d3dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 16,812,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NACvu1lCz_sd"
   },
   "source": [
    "- Network의 모든 weight가 학습되는 모형임\n",
    "- VGG16에서 가져온 부분은 학습을 하지 않고 weight를 고정시킬 것이므로 아래와 같이  `trainable=False`를 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T05:35:20.718135Z",
     "start_time": "2018-07-14T05:35:20.714046Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "xnTHC2Wnz_se",
    "outputId": "0a046f02-e3b6-45e4-a881-c58ddb49663d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 2,097,665\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bdJ6CXdYz_sj"
   },
   "source": [
    "- `Non-trainable params`의 수가 `vgg16` layer의 parameter 수와 동일함을 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zfu1NYDxz_sk"
   },
   "source": [
    "#### Defining image generators and fitting the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T05:35:29.696447Z",
     "start_time": "2018-07-14T05:35:29.353683Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ShvcHFWyz_sm",
    "outputId": "15dadbab-5c3e-4037-c74c-df1d14e0c34b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8a2O3U2Hz_sq",
    "outputId": "c70e1a48-dd76-4ecd-f90e-10e07d23119e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\keras\\lib\\site-packages\\keras\\callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\keras\\lib\\site-packages\\keras\\callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\keras\\lib\\site-packages\\keras\\callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\keras\\lib\\site-packages\\keras\\callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Failed to create a directory: /tmp/logs/trasferTue Dec 10 17:05:14 2019; Invalid argument",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-74393fbfd679>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m       \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m       \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m       callbacks = [tensorboard])\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\envs\\keras\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\keras\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\keras\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mcallback_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m     callbacks.set_params({\n\u001b[0;32m     96\u001b[0m         \u001b[1;34m'epochs'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\keras\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mset_model\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\keras\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mset_model\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    852\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    853\u001b[0m             self.writer = tf.summary.FileWriter(self.log_dir,\n\u001b[1;32m--> 854\u001b[1;33m                                                 self.sess.graph)\n\u001b[0m\u001b[0;32m    855\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\summary\\writer\\writer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, logdir, graph, max_queue, flush_secs, graph_def, filename_suffix, session)\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m       event_writer = EventFileWriter(logdir, max_queue, flush_secs,\n\u001b[1;32m--> 367\u001b[1;33m                                      filename_suffix)\n\u001b[0m\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_closed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\summary\\writer\\event_file_writer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, logdir, max_queue, flush_secs, filename_suffix)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logdir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIsDirectory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMakeDirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_logdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_queue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQueue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     self._ev_writer = pywrap_tensorflow.EventsWriter(\n",
      "\u001b[1;32mD:\\anaconda\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mrecursive_create_dir\u001b[1;34m(dirname)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m   \"\"\"\n\u001b[1;32m--> 438\u001b[1;33m   \u001b[0mrecursive_create_dir_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mrecursive_create_dir_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m   \"\"\"\n\u001b[1;32m--> 453\u001b[1;33m   \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRecursivelyCreateDir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Failed to create a directory: /tmp/logs/trasferTue Dec 10 17:05:14 2019; Invalid argument"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              metrics=['acc'])\n",
    "\n",
    "import time \n",
    "now = time.strftime(\"%c\")\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='/tmp/logs/trasfer'+now)\n",
    "model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=5, # 느린 학습속도 때문에 예시로 5 epoch만 학습\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,\n",
    "      callbacks = [tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dgy0xFr0z_st"
   },
   "source": [
    "- `conv_base`에 해당하는 weight를 학습하지는 않지만 새로운 이미지 학습데이터가 VGG16의 모든 convolution layer를 통과해야 하기 때문에 학습속도가 이전에 비해 현저히 느림\n",
    "- Data augmentation을 통해 overfitting 방지 효과가 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lQqRQkvBz_su"
   },
   "source": [
    "\n",
    "## 7.2 Fine-tuning\n",
    "- 기존 network에서 가져온 base에 사용자의 목적에 맞는 dense layer를 추가하는 부분은 이전과 동일 \n",
    "- Base model의 weight을 모두 고정하지 않고 일부 top layer를 학습과정에서 함께 업데이트\n",
    "- 주어진 문제에 더 적합하도록 모형을 조정하는 과정 \n",
    "\n",
    "![fine-tuning VGG16](https://s3.amazonaws.com/book.keras.io/img/ch5/vgg16_fine_tuning.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T06:04:15.597998Z",
     "start_time": "2018-07-14T06:04:15.513022Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "nIi6M_6Vz_sw"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T06:04:15.770288Z",
     "start_time": "2018-07-14T06:04:15.760510Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "i5z1fB3Rz_tA",
    "outputId": "beb704b1-f257-4c9a-e299-44d15a8d515b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T_VLp3Ikz_tG"
   },
   "source": [
    "#### Selecting layers to be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fcojDGmoz_tK",
    "outputId": "6efd922a-2494-47fc-b168-e83284e90631"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x1f8571c1a08>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1f85f774b48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1f860688448>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1f86069c408>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1f8606c9bc8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1f8606cc048>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1f8606dbcc8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1f8606e5308>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1f8606eb9c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1f8606f0c48>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1f8606f2648>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1f860704d48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1f860707348>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1f860711f48>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1f86071bbc8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1f860722e88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1f860727548>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1f860730b88>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1f860739ec8>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_base.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T06:04:16.974864Z",
     "start_time": "2018-07-14T06:04:16.964981Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "idKEC8qLz_tQ"
   },
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wkPtxjXjz_tU"
   },
   "source": [
    "- `block5_conv1`, `block5_conv2`,  `block5_conv3`를 fine-tune 시도 \n",
    "    - 앞의 layer들은 비교적 일반적이고 재사용 가능한 feature를 학습\n",
    "    - 너무 많은 parameter를 학습시키면 overfitting의 위험이 있음 (특히 새로운 데이터의 수가 적을 때)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T06:04:18.288092Z",
     "start_time": "2018-07-14T06:04:18.280811Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "OQCDriYvz_tW",
    "outputId": "a97b183e-628b-4ddb-98a3-657f5da4486d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 7,079,424\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T06:13:47.328573Z",
     "start_time": "2018-07-14T06:04:18.900782Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "MrPyhC2uz_td",
    "outputId": "009088ec-d727-476e-9ee3-5b6104ca8038",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 486s 5s/step - loss: 0.5313 - acc: 0.7360 - val_loss: 0.3207 - val_acc: 0.8670\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 473s 5s/step - loss: 0.3720 - acc: 0.8330 - val_loss: 0.2501 - val_acc: 0.8890\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 472s 5s/step - loss: 0.3178 - acc: 0.8625 - val_loss: 0.2328 - val_acc: 0.8980\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 469s 5s/step - loss: 0.2884 - acc: 0.8685 - val_loss: 0.2096 - val_acc: 0.9090\n",
      "Epoch 5/30\n",
      " 60/100 [=================>............] - ETA: 2:17 - loss: 0.2489 - acc: 0.8983"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history2 = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=30,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7SpWAQ_Jz_tg"
   },
   "outputs": [],
   "source": [
    "#model.save('cats_and_dogs_small_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T06:13:47.693386Z",
     "start_time": "2018-07-14T06:13:47.330840Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "zPPL7BU1z_tj",
    "outputId": "b4012b9a-c471-4892-dfbf-0d4e767149cf"
   },
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cp9dJ4bNz_tn",
    "outputId": "b2698064-de66-4494-c6e8-e243f945180a"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('cats_and_dogs_small_3.h5')\n",
    "model.evaluate_generator(test_generator, steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b502Xzvzz_tw"
   },
   "source": [
    "\n",
    "References\n",
    "- https://www.coursera.org/specializations/deep-learning\n",
    "- [Hands on Machine Learning with Scikit-Learn  and Tensorflow, Aurélien Géron]( http://www.hanbit.co.kr/store/books/look.php?p_code=B9267655530)\n",
    "- [Deep Learning with Python, François Chollet,](https://www.manning.com/books/deep-learning-with-python)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "name": "7_Transfer Learning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
